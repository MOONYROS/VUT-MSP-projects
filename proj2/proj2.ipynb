{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSP projekt 2 - Ondřej Lukášek (xlukas15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol 1 - Věrohodnost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Začnu tím, že si naimportuji potřebné knihovny, se kterými budu v projektu pracovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následně si načtu sheet, který obsahuje data, se kterými budu pracovat.\n",
    "\n",
    "Předpřipravím si parametry tak, abych je mohl rovnou použít dál."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Data_2024.xlsx'\n",
    "sheet_name = 'Data_věrohodnost'\n",
    "\n",
    "data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "times = data['doba práce v oboru [roky]'].dropna().to_numpy()\n",
    "censored = data['censored'].to_numpy()\n",
    "\n",
    "initial_params = (1.5, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bod 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood: -740.8976732574417\n",
      "Derivatives: [64.24195393 77.00791218]\n"
     ]
    }
   ],
   "source": [
    "def weibull_log_likelihood(params, times, censored):\n",
    "    k, lam = params\n",
    "    \n",
    "    # logaritmizace pro necenzurovana data\n",
    "    log_f = np.log(k) - k * np.log(lam) + (k - 1) * np.log(times) - (times / lam)**k\n",
    "    # logaritmizace pro cenzurovana data\n",
    "    log_sf = - (times / lam)**k\n",
    "    \n",
    "    # spojeni logaritmu pro necenzurovana a cenzurovana data\n",
    "    likelihood = (1 - censored) * log_f + censored * log_sf\n",
    "\n",
    "    return likelihood.sum()\n",
    "\n",
    "\n",
    "# MOZNA SMAZAT???\n",
    "def weibull_log_likelihood_derivatives(params, times, censored):\n",
    "    k, lam = params\n",
    "\n",
    "    # predvypocitani konstant, co se budou v derivacich opakovat\n",
    "    t_lam_k = (times / lam)**k\n",
    "    log_t_lam = np.log(times / lam)\n",
    "    \n",
    "    # parcialni derivace logaritmu podle parametru k\n",
    "    dL_dk = np.sum((1 - censored) * (1 / k + log_t_lam - t_lam_k * log_t_lam) + censored * (-t_lam_k * log_t_lam))\n",
    "    # parcialni derivace logaritmu podle parametru lambda\n",
    "    dL_dlam = np.sum((1 - censored) * (-k / lam + k * t_lam_k / lam) + censored * (k * t_lam_k / lam))\n",
    "    \n",
    "    return np.array([dL_dk, dL_dlam])\n",
    "\n",
    "\n",
    "log_likelihood = weibull_log_likelihood(initial_params, times, censored)\n",
    "derivatives = weibull_log_likelihood_derivatives(initial_params, times, censored)\n",
    "\n",
    "print(f'Log-likelihood: {log_likelihood}')\n",
    "print(f'Derivatives: {derivatives}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bod 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal likelihood estimation:\n",
      "Shape (k): 6.172808847674017\n",
      "Scale (lambda): 7.4294603426242265\n"
     ]
    }
   ],
   "source": [
    "def neg_weibull_log_likelihood(params, times, censored):\n",
    "    return -weibull_log_likelihood(params, times, censored)\n",
    "\n",
    "result = opt.minimize(\n",
    "    fun=neg_weibull_log_likelihood,\n",
    "    x0=initial_params,\n",
    "    args=(times, censored),\n",
    "    method='L-BFGS-B',\n",
    "    bounds=[(0.1, None), (0.1, None)]\n",
    ")\n",
    "\n",
    "optimal_shape, optimal_scale = result.x\n",
    "\n",
    "print('Maximal likelihood estimation:')\n",
    "print(f'Shape (k): {optimal_shape}')\n",
    "print(f'Scale (lambda): {optimal_scale}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bod 3\n",
    "\n",
    "Pomocí věrohodnostního poměru otestujte hypotézu, že exponenciální rozdělení je postačujícím modelem zapsaných dat (Parametr tvaru = 1).\n",
    "\n",
    "By default je distribuční funkce (pro $ x \\geq 0 $) exponenciálního rozdělení:\n",
    "\n",
    "$ f(x; \\lambda) = \\lambda e^{-\\lambda x} $\n",
    "\n",
    "Logaritmus potom bude:\n",
    "\n",
    "$ \\ell(x; \\lambda) = \\ln \\lambda - \\lambda x $\n",
    "\n",
    "Log-likelihood potom je:\n",
    "\n",
    "$ \\ell(\\lambda) = \\sum_{i=1}^n \\left[ \\ln \\lambda - \\lambda x_i \\right]  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood ratio: 592.3898153427439\n",
      "Critical value (alpha = 0.05): 3.841458820694124\n",
      "Zamítáme nulovou hypotézu. Exponenciální rozdělení není postačující.\n"
     ]
    }
   ],
   "source": [
    "def exponential_log_likelihood(lam, times, censored):\n",
    "    log_f = np.log(lam) - lam * times\n",
    "    log_sf = -lam * times\n",
    "\n",
    "    likelihood = (1 - censored) * log_f + censored * log_sf\n",
    "    return np.sum(likelihood)\n",
    "\n",
    "\n",
    "result_exp = opt.minimize(\n",
    "    fun=lambda lam: -exponential_log_likelihood(lam[0], times, censored),\n",
    "    x0=[1.0],\n",
    "    bounds=[(0.1, None)],\n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "lambda_exp = result_exp.x[0]\n",
    "log_likelihood_exp = -result_exp.fun\n",
    "\n",
    "k_weibull, lambda_weibull = result.x\n",
    "result_weibull = -result.fun\n",
    "\n",
    "# VYPOCET VEROHODNOSTNIHO POMERU\n",
    "LR = 2 * (result_weibull - log_likelihood_exp)\n",
    "\n",
    "alpha = 0.05\n",
    "critical_value = stats.chi2.ppf(1 - alpha, df=1)\n",
    "\n",
    "print(f'Likelihood ratio: {LR}')\n",
    "print(f'Critical value (alpha = {alpha}): {critical_value}')\n",
    "\n",
    "if LR > critical_value:\n",
    "    print('Zamítáme nulovou hypotézu. Exponenciální rozdělení není postačující.')\n",
    "else:\n",
    "    print('Nulovou hypotézu nezamítáme. Exponenciální rozdělení je postačující.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bod 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol 2 - Regrese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
